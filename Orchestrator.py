#################################################################
#																#
# -Project:		Prevalence of Types of ASEPs in Windows malware #
# -File:		Orchestrator.py									#
# -Author:		Carlos Borau GonzÃ¡lez | NIP: 778280				#
# -Description: Malware sample analysis workflow orchestrator	#
#					responsible for the coordination among the  #
#					multiple processes invlolved in this task:	#
#					-Sample Digestion							#
#					-Sample Submission for Analysis				#
#					-Analysis Logs Gathering					#
#					-Analysis Logs Parsing and Sample Labeling	#
#					-Analysis Logs, Results and Sample Storing	#
#																#
#################################################################

# Workflow components imports
from Digester 	import Digester
from Analyzer 	import Analyzer,	AnalyzerMode
from Labeler	import Labeler,		LabelerMode
from Storer		import Storer

# Utility imports



from multiprocessing import Process, Value, Manager

# RPC comunication imports
import xmlrpc.server as srv
import xmlrpc.client as cli

class Orchestrator:

	# Auxiliar class to interact with worker threads
	class WorkerHandler:
	
		def __init__(self, process, resource=None, done=False):
		
			self.process = process
			self.resource = resource
			self.done = done
			
		def isDone(self):
			
			return self.done
			
		def stop(self):
		
			self.done = True
			self.process.join()
			
			return self.resource
			
		def setResource(self, resource):
		
			self.resource = resource
			return self.resource

	
	def __init__(self, overwatch_directory, samples_directory, results_directory,
	 processed_hashes=[], remoteAnalysis=False, remoteLabeling=True):
	
		self.AnalyzerMode = AnalyzerMode.Remote if remoteAnalysis else AnalyzerMode.Local
		self.LabelerMode  = LabelerMode.Remote  if remoteLabeling else LabelerMode.Local
		
		self.Digester = Digester(overwatch_directory, samples_directory, processed_hashes)
		self.Digester.start(60)
		
		self.Storer = Storer(results_directory)
		
		self.ResourceManager = Manager()
		self.WorkersID = Value('i', 0)
		self.AnalysisWorkers = self.ResourceManager.dict()
		self.LabelingWorkers = self.ResourceManager.dict()
		self.AvailableLogs = self.ResourceManager.Queue()
		
	def stop(self):
	
		self.Digester.stop()
		
		self.SamplesToAnalyze 	= []
		self.SamplesToLabel		= []
		
		for worker in self.AnalysisWorkers:
			self.SamplesToAnalyze.append(self.delAnalysisWorker(worker))
			
		for worker in self.LabelingWorkers:
			self.SamplesToLabel.append(self.delLabelingWorker(worker))
			
			
	#########################################################
	#														#
	#					Analysis Workers					#
	#														#
	#########################################################
			
	def analysisWorkerProcess(self, ID, addr):
	
		if(self.AnalyzerMode == AnalyzerMode.Local):
			analyzer = Analyzer(AnalyzerMode.Local)
		else:
			analyzer = cli.ServerProxy('http://{0}'.format(addr))
			
		finished = False
		
		while(not finished):
		
			# Get sample to analyze
			sample = self.AnalysisWorkers[ID].setResource(self.Digester.getSample())
			
			# Submit sample to analyzer
			analysisTask = analyzer.SubmitSample(sample)
			
			# Wait for the analysis to be completed
			while(analyzer.CheckStatus(analysisTask) == "pending"):
				time.sleep(30)
				
			if(analyzer.CheckStatus(analysisTask) == "done"):
				# Analysis completed -> Request Logs and queue them to be parsed
				availableLogs = analyzer.AvailableLogs(analysisTask)
				
				sampleID = self.storer.CreateSampleTmpDir(sample)
				
				if(availableLogs):
				
					# Check drakrun log
					log_content = analyzer.GetLog(analysisTask, "drakrun") if ("drakrun" in availableLogs) else ""
						
					if(log_content):
						# Drakrun log properly generated
						self.storer.CreateSampleResource(sampleID, "drakrun.log", log_content)
						
						# Check syscall log
						log_content = analyzer.GetLog(analysisTask, "syscall") if ("syscall" in availableLogs) else ""
						
						if(log_content):
							# Syscall log properly generated
							logPath = self.storer.CreateSampleResource(sampleID, "syscall.log", log_content)
							
							# Queue the log to be parsed and labeled by a labeling worker
							self.AvailableLogs.put((sampleID, logPath))
						
						else:
							# Tried but failed to analyze the sample
							self.storer.StoreSample(sampleID)
						
				else:
					# Analysis failure -> No logs generated
					log_content = "Analysis Failure | NO_LOGS_GENERATED"
					self.storer.CreateSampleResource(sampleID, "INFO.log", log_content)
					self.storer.StoreSample(sampleID)
					
					
			else:
				# Analysis failure -> Requeue the sample to be analyzed later
				self.Digester.putSample(sample)

			# Marked for stop?
			finished = self.AnalysisWorkers[ID].isDone()
					
		
	def addAnalysisWorker(self, ip=None, port=None):
	
		if(self.AnalyzerMode == AnalyzerMode.Local):
		
			# New local process
			ID = self.WorkersID
			self.WorkersID += 1
			addr = None
			
		else:
		
			ID = ip
			addr = ip + ':' + port
			
			if(self.AnalysisWorkers.get(ip) != None): 
			
				# Fallen worker reconnects before heartbeat detection
				sample = delAnalysisWorker(ID)
				self.Digester.putSample(sample)
		
		p = Process(target=self.analysisWorkerProcess, args=(ID,addr))
		p.start()
		self.AnalysisWorkers[ID] = WorkerHandler(p)
	
	
	def delAnalysisWorker(self, ID):
	
		sample = self.AnalysisWorkers[ID].stop()
		
		return sample
	
	
	#########################################################
	#														#
	#					Labeling Workers					#
	#														#
	#########################################################
	
	def labelingWorkerProcess(self, ID, addr):
		
		if(self.LabelerMode == LabelerMode.Local):
			labeler = Labeler(LabelerMode.Local)
		else:
			labeler = cli.ServerProxy('http://{0}'.format(addr))
		
		finished = False
		
		while(not finished):
		
			# Get log to parse
			(sampleID, log) = self.LabelingWorkers[ID].setResource(self.AvailableLogs.get())
			
			# Submit the log for parsing
			results = labeler.SubmitLog(log)

			# Create the corresponding resource for the sample and save it
			self.storer.CreateSampleResource(sampleID, "labeling.log", results)
			self.storer.StoreSample(sampleID)
		
			# Marked for stop?
			finished = self.LabelingWorkers[ID].isDone()
	
	
	def addLabelingWorker(self, ip=None, port=None):
	
		if(self.LabelerMode == LabelerMode.Local):
		
			# New local process
			ID = self.WorkersID
			self.WorkersID += 1
			addr = None
			
		else:
			
			ID = ip
			addr = ip + ':' + port
			
			if(self.LabelingWorkers.get(ip) != None): 
			
				# Fallen worker reconnects before heartbeat detection
				(sampleID, log) = self.delLabelingWorker(ID)
				self.AvailableLogs.put((sampleID, log))
			
		
		p = Process(target=self.labelingWorkerProcess, args=(ID,addr))
		p.start()
		self.LabelingWorkers[ID] = WorkerHandler(p)
	
	
	def delLabelingWorker(self, ID):
	
		(sampleID, log) = self.LabelingWorkers[ID].stop()
		
		return (sampleID, log)
	
	
	
